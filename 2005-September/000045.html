<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Maay-svncheckins] r71 - in trunk/maay: . test test/data
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/maay-svncheckins/2005-September/index.html" >
   <LINK REL="made" HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r71%20-%20in%20trunk/maay%3A%20.%20test%20test/data&In-Reply-To=%3C200509231411.j8NEBls9005615%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000044.html">
   <LINK REL="Next"  HREF="000046.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Maay-svncheckins] r71 - in trunk/maay: . test test/data</H1>
    <B>Adrien Di Mascio at BerliOS</B> 
    <A HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r71%20-%20in%20trunk/maay%3A%20.%20test%20test/data&In-Reply-To=%3C200509231411.j8NEBls9005615%40sheep.berlios.de%3E"
       TITLE="[Maay-svncheckins] r71 - in trunk/maay: . test test/data">adimasci at berlios.de
       </A><BR>
    <I>Fri Sep 23 16:11:47 CEST 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="000044.html">[Maay-svncheckins] r70 - trunk/maay
</A></li>
        <LI>Next message: <A HREF="000046.html">[Maay-svncheckins] r72 - trunk/maay
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#45">[ date ]</a>
              <a href="thread.html#45">[ thread ]</a>
              <a href="subject.html#45">[ subject ]</a>
              <a href="author.html#45">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: adimasci
Date: 2005-09-23 16:11:46 +0200 (Fri, 23 Sep 2005)
New Revision: 71

Added:
   trunk/maay/test/data/encoded.html
   trunk/maay/test/data/latin1.txt
   trunk/maay/test/data/latin1.xml
   trunk/maay/test/data/utf16.txt
   trunk/maay/test/data/utf32.txt
   trunk/maay/test/data/utf8.txt
   trunk/maay/test/data/utf8.xml
   trunk/maay/test/data/utf8noencoding.xml
Removed:
   trunk/maay/test/data/DONOTREMOVEME
Modified:
   trunk/maay/converter.py
   trunk/maay/test/test_querier.py
   trunk/maay/test/test_texttool.py
   trunk/maay/texttool.py
Log:
added encoding management on indexer/converter. 


Modified: trunk/maay/converter.py
===================================================================
--- trunk/maay/converter.py	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/converter.py	2005-09-23 14:11:46 UTC (rev 71)
@@ -18,11 +18,15 @@
 
 and that's it. Next time the indexer will try to index a PDF file,
 it will use your converter.
+
 &quot;&quot;&quot;
 __revision__ = '$Id$'
 
+# XXX: need to handle file encodings
+
 import os
 from mimetypes import guess_type
+from tempfile import mkdtemp
 
 from maay.texttool import TextParser, MaayHTMLParser as HTMLParser
 
@@ -47,6 +51,8 @@
     &quot;&quot;&quot;base converter class&quot;&quot;&quot;
     __metaclass__ = MetaConverter
     OUTPUT_TYPE = 'text'
+    # None means &quot;let the text parser guess the encoding&quot;
+    OUTPUT_ENCODING = None
 
     def getParser(self):
         if self.OUTPUT_TYPE == 'html':
@@ -60,7 +66,7 @@
         :returns: a word-vector
         &quot;&quot;&quot;
         parser = self.getParser()
-        return parser.parseFile(filename)
+        return parser.parseFile(filename, self.OUTPUT_ENCODING)
 
 
 class RawTextConverter(BaseConverter):
@@ -76,21 +82,34 @@
 class CommandBasedConverter(BaseConverter):
     COMMAND = None
     def extractWordsFromFile(self, filename):
-        command_args = {'input' : filename, 'output' : '/tmp/out.txt'}
+        outputDir = mkdtemp()
+        outputFile = os.path.join(outputDir, 'out.txt')
+        command_args = {'input' : filename, 'output' : outputFile}
         cmd = self.COMMAND % command_args
         print &quot;Executing %r&quot; % cmd
         errcode = os.system(cmd)
-        if errcode == 0: # OK
-            parser = self.getParser()
-            return parser.parseFile('/tmp/out.txt')
-        else:
-            raise IndexationFailure('Unable to index %r' % filename)
+        try:
+            if errcode == 0: # OK
+                parser = self.getParser()
+                return parser.parseFile(outputFile, self.OUTPUT_ENCODING)
+            else:
+                raise IndexationFailure('Unable to index %r' % filename)
+        finally:
+            if os.path.isfile(outputFile):
+                os.remove(outputFile)
+            os.rmdir(outputDir)
 
+class PDFConverter(CommandBasedConverter):
+    &quot;&quot;&quot;among other things, man pdftotext says ::
 
-class PDFConverter(CommandBasedConverter):
+      -enc encoding-name
+        Sets the encoding to use for text output [...] Default is
+        &quot;Latin1&quot;
+    &quot;&quot;&quot;
     COMMAND = &quot;pdftotext -htmlmeta %(input)s %(output)s&quot;
     OUTPUT_TYPE = 'html'
     MIME_TYPE = 'application/pdf'
+    OUTPUT_ENCODING = 'iso-8859-1'
 
 class PSConverter(CommandBasedConverter):
     COMMAND = &quot;ps2ascii %(input)s %(output)s&quot;

Deleted: trunk/maay/test/data/DONOTREMOVEME
===================================================================
--- trunk/maay/test/data/DONOTREMOVEME	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/DONOTREMOVEME	2005-09-23 14:11:46 UTC (rev 71)
@@ -1,2 +0,0 @@
-# please
-

Added: trunk/maay/test/data/encoded.html
===================================================================
--- trunk/maay/test/data/encoded.html	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/encoded.html	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1,11 @@
+&lt;html&gt;
+  &lt;head&gt;
+    &lt;title&gt;maille Maay&lt;/title&gt;
+    &lt;meta http-equiv=&quot;Content-Type&quot;
+	  content=&quot;text/html;charset=latin1&quot; /&gt;
+  &lt;/head&gt;
+  &lt;body&gt;Hello &#233;t&#233; world
+  This is &lt;a href=&quot;something.com&quot;&gt;a link&lt;/a&gt;
+  and this is &lt;a href=&quot;somethingelse.com&quot;&gt;another link&lt;/a&gt;
+  &lt;/body&gt;
+&lt;/html&gt;

Added: trunk/maay/test/data/latin1.txt
===================================================================
--- trunk/maay/test/data/latin1.txt	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/latin1.txt	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1 @@
+c'est l'&#233;t&#233;

Added: trunk/maay/test/data/latin1.xml
===================================================================
--- trunk/maay/test/data/latin1.xml	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/latin1.xml	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1,5 @@
+&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot; ?&gt;
+
+&lt;root&gt;
+  &lt;bim bam=&quot;boum&quot;&gt;&#233;t&#233;&lt;/bim&gt;
+&lt;/root&gt;

Added: trunk/maay/test/data/utf16.txt
===================================================================
(Binary files differ)


Property changes on: trunk/maay/test/data/utf16.txt
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/maay/test/data/utf32.txt
===================================================================
(Binary files differ)


Property changes on: trunk/maay/test/data/utf32.txt
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/maay/test/data/utf8.txt
===================================================================
--- trunk/maay/test/data/utf8.txt	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/utf8.txt	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1 @@
+c'est l'&#195;&#169;t&#195;&#169;

Added: trunk/maay/test/data/utf8.xml
===================================================================
--- trunk/maay/test/data/utf8.xml	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/utf8.xml	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1,5 @@
+&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
+
+&lt;root&gt;
+  &lt;bim bam=&quot;boum&quot;&gt;&#195;&#169;t&#195;&#169;&lt;/bim&gt;
+&lt;/root&gt;

Added: trunk/maay/test/data/utf8noencoding.xml
===================================================================
--- trunk/maay/test/data/utf8noencoding.xml	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/data/utf8noencoding.xml	2005-09-23 14:11:46 UTC (rev 71)
@@ -0,0 +1,5 @@
+&lt;?xml version=&quot;1.0&quot;?&gt;
+
+&lt;root&gt;
+  &lt;bim bam=&quot;boum&quot;&gt;&#195;&#169;t&#195;&#169;&lt;/bim&gt;
+&lt;/root&gt;

Modified: trunk/maay/test/test_querier.py
===================================================================
--- trunk/maay/test/test_querier.py	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/test_querier.py	2005-09-23 14:11:46 UTC (rev 71)
@@ -6,7 +6,7 @@
 
 from logilab.common.testlib import MockConnection
 from logilab.common.db import get_connection
-from maay.querier import MaayQuerier, normalize_text, Document, FileInfo
+from maay.querier import MaayQuerier, normalizeText, Document, FileInfo
 
 
 
@@ -31,9 +31,10 @@
         self.assertEquals(list(answ), [])
 
     def testIndexDocument(self):
-        text = &quot;&quot;&quot;Le tartuffe, de Jean-Baptiste Poquelin, dit Moli&#232;re.
+        text = u&quot;&quot;&quot;Le tartuffe, de Jean-Baptiste Poquelin, dit Moli&#232;re.
 
 Le petit chat est mort.&quot;&quot;&quot;
+        text = normalizeText(text)
         digest = sha.sha(text).hexdigest()
         cursor = self.cnx.cursor()
         # At this point, database should be emtpy, so no document
@@ -54,8 +55,8 @@
         self.assertEquals(matchingDocs[0].text, text)
         
 
-    def test_normalize_text(self):
-        self.assertEquals(normalize_text(&quot;&#201;t&#249;&#239;&#196;&#231;&quot;), &quot;etuiac&quot;)
+    def test_normalizeText(self):
+        self.assertEquals(normalizeText(u&quot;&#201;t&#249;&#239;&#196;&#231;&quot;), &quot;etuiac&quot;)
 
 
 if __name__ == '__main__':

Modified: trunk/maay/test/test_texttool.py
===================================================================
--- trunk/maay/test/test_texttool.py	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/test/test_texttool.py	2005-09-23 14:11:46 UTC (rev 71)
@@ -1,20 +1,24 @@
+# -*- coding: ISO-8859-1 -*-
 &quot;&quot;&quot;unit tests for Text and HTML parsers&quot;&quot;&quot;
 
 import unittest
+from os.path import join, dirname
 
-from maay.texttool import MaayHTMLParser
+from maay.texttool import MaayHTMLParser, guessEncoding
 
-ROW_TEXT = &quot;foo bar baz top bim bam boum&quot;
+ROW_TEXT = u&quot;foo &#233;t&#233; bar baz top bim bam boum&quot;
 
-SIMPLE_HTML = &quot;&quot;&quot;&lt;html&gt;
+SIMPLE_HTML = u&quot;&quot;&quot;&lt;html&gt;
 &lt;head&gt;&lt;title&gt;maille Maay&lt;/title&gt;&lt;/head&gt;
-&lt;body&gt;Hello world
+&lt;body&gt;Hello &#233;t&#233; world
 This is &lt;a href=&quot;something.com&quot;&gt;a link&lt;/a&gt;
 and this is &lt;a href=&quot;somethingelse.com&quot;&gt;another link&lt;/a&gt;
 &lt;/body&gt;
 &lt;/html&gt;
 &quot;&quot;&quot;
 
+DATADIR = join(dirname(__file__), 'data')
+
 class HTMLParserTC(unittest.TestCase):
 
     def setUp(self):
@@ -24,15 +28,47 @@
         html = '&lt;body&gt;%s&lt;/body&gt;' % ROW_TEXT
         title, text, links, offset = self.parser.parseString(html)
         self.assertEquals(title, '')
-        self.assertEquals(text, ROW_TEXT)
+        self.assertEquals(text, ROW_TEXT.replace(u'&#233;', 'e'))
         self.assertEquals(links, [])
 
     def testParseSimpleHtml(self):
         title, text, links, offset = self.parser.parseString(SIMPLE_HTML)
         self.assertEquals(title, 'maille Maay')
-        self.assertEquals(text, 'hello world this is a link and this is another link')
+        self.assertEquals(text, 'hello ete world this is a link and this is another link')
         self.assertEquals(links, ['something.com', 'somethingelse.com'])
     
 
+    def testParseHtmlFileWithEncoding(self):
+        filename = join(DATADIR, 'encoded.html')
+        title, text, links, offset = self.parser.parseFile(filename, 'iso-8859-1')
+        self.assertEquals(title, 'maille Maay')
+        self.assertEquals(text, 'hello ete world this is a link and this is another link')
+        self.assertEquals(links, ['something.com', 'somethingelse.com'])
+        
+    def testParseHtmlFileAndGuessEncoding(self):
+        filename = join(DATADIR, 'encoded.html')
+        title, text, links, offset = self.parser.parseFile(filename)
+        self.assertEquals(title, 'maille Maay')
+        self.assertEquals(text, 'hello ete world this is a link and this is another link')
+        self.assertEquals(links, ['something.com', 'somethingelse.com'])
+        
+    def testGuessEncoding(self):
+        self.assertEquals(guessEncoding(join(DATADIR, 'utf8.txt')), 'UTF-8')
+        self.assertEquals(guessEncoding(join(DATADIR, 'utf16.txt')), 'UTF-16')
+        # self.assertEquals(guessEncoding(join(DATADIR, 'utf16be.txt')), 'UTF-16')
+        self.assertEquals(guessEncoding(join(DATADIR, 'utf32.txt')), 'UTF-32')
+        # self.assertEquals(guessEncoding(join(DATADIR, 'utf32be.txt')), 'UTF-32')
+        self.assertEquals(guessEncoding(join(DATADIR, 'latin1.xml')), 'ISO-8859-1')
+        self.assertEquals(guessEncoding(join(DATADIR, 'utf8.xml')), 'UTF-8')
+        self.assertEquals(guessEncoding(join(DATADIR, 'latin1.xml')), 'ISO-8859-1')
+        self.assertEquals(guessEncoding(join(DATADIR, 'encoded.html')), 'ISO-8859-1')
+
+    def test_normalizeHTMLEncoding(self):
+        data = [
+            'latin1', 'ISO-8859-1',
+            'iso-88591', 'ISO-8859-1',
+            
+            ]
+
 if __name__ == '__main__':
     unittest.main()

Modified: trunk/maay/texttool.py
===================================================================
--- trunk/maay/texttool.py	2005-09-23 14:10:22 UTC (rev 70)
+++ trunk/maay/texttool.py	2005-09-23 14:11:46 UTC (rev 71)
@@ -1,3 +1,4 @@
+# -*- coding: ISO-8859-1 -*-
 &quot;&quot;&quot;this module provide text / parsing tools&quot;&quot;&quot;
 
 __revision__ = '$Id$'
@@ -3,21 +4,87 @@
 
 from HTMLParser import HTMLParser
-        
-class TextParser:
-    def parseFile(self, filename):
+import codecs
+import re
+
+CHARSET_RGX = re.compile('charset=([^\s&quot;]*)', re.I | re.S | re.U)
+XML_ENCODING_RGX = re.compile('&lt;\?xml version=[^\s]*\s*encoding=([^\s]*)\s*\?&gt;', re.I | re.S | re.U)
+
+def normalizeHtmlEncoding(htmlEncoding):
+    # XXX FIXME: this function probably already exists somewhere ...
+    if htmlEncoding in ('iso8859-1', 'iso-latin1', 'iso-latin-1', 'latin-1',
+                        'latin1'):
+        return 'ISO-8859-1'
+    # default, return original one
+    return htmlEncoding
+
+
+def guessEncoding(filename):
+    &quot;&quot;&quot;try to guess encoding from a buffer
+        Bytes  	Encoding Form
+        00 00 FE FF 	UTF-32, big-endian
+        FF FE 00 00 	UTF-32, little-endian
+        FE FF 	        UTF-16, big-endian
+        FF FE 	        UTF-16, little-endian
+        EF BB BF 	UTF-8
+    &quot;&quot;&quot;
+    stream = file(filename, 'rb')
+    try:
+        buffer = stream.read(4)
+        # try to guess from BOM
+        if buffer[:4] in (codecs.BOM_UTF32_BE, codecs.BOM_UTF32_LE):
+            return 'UTF-32'
+        elif buffer[:2] in (codecs.BOM_UTF16_BE, codecs.BOM_UTF16_LE):
+            return 'UTF-16'
+        elif buffer[:3] == codecs.BOM_UTF8:
+            return 'UTF-8'
+        buffer += stream.read()
+        # try to get charset declaration
+        # FIXME: should we check it's html before ?
+        m = CHARSET_RGX.search(buffer)
+        if m is not None:
+            return normalizeHtmlEncoding(m.group(1))
+        # check for xml encoding declaration
+        if buffer.lstrip().startswith('&lt;?xml'):
+            m = XML_ENCODING_RGX.match(buffer)
+            if m is not None:
+                return m.group(1)[1:-1].upper()
+            # xml files with no encoding declaration default to UTF-8
+            return 'UTF-8'
+        try:
+            data = unicode(buffer, 'utf-8')
+            return 'UTF-8'
+        except UnicodeError:
+            return 'ISO-8859-1'
+    finally:
+        stream.close()
+
+
+class AbstractParser:
+    &quot;&quot;&quot;base-class for file parsers&quot;&quot;&quot;
+    def parseFile(self, filename, encoding=None):
         &quot;&quot;&quot;returns a 4-uple (title, normalized_text, links, offset)
-        
-        Aglorithm taken from original texttotext implementation
+        TODO: port original code from htmltotext
+        :param encoding: if None, then need to be guessed
         &quot;&quot;&quot;
-        content = file(filename).read()
-        return self.parseString(content)
+        encoding = encoding or guessEncoding(filename)
+        stream = codecs.open(filename, 'r', encoding)
+        try:
+            return self.parseString(stream.read())
+        finally:
+            stream.close()
 
     def parseString(self, source):
-        result = normalize_text(source)
+        raise NotImplementedError()
+
+
+class TextParser(AbstractParser):
+
+    def parseString(self, source):
+        result = normalizeText(source)
         title = result[:60]
         return title, result, [], 0
         
 
-class MaayHTMLParser(HTMLParser):
+class MaayHTMLParser(AbstractParser, HTMLParser):
     def __init__(self):
         HTMLParser.__init__(self)
@@ -49,17 +116,9 @@
         elif self.parsingBody:
             self.textbuf.append(data)
     
-    def parseFile(self, filename):
-        &quot;&quot;&quot;returns a 4-uple (title, normalized_text, links, offset)
-        TODO: port original code from htmltotext
-        &quot;&quot;&quot;
-        # XXX: really dummy implementation !!
-        source = file(filename).read()
-        return self.parseString(source)
-
     def parseString(self, source):
         self.feed(source)
-        result = normalize_text(''.join(self.textbuf))
+        result = normalizeText(''.join(self.textbuf))
         return self.title, result, self.links, 0
 
 
@@ -106,11 +165,16 @@
     'uuuu'
     'y'
     )
+_table = [ord(c) for c in _table]
 del maketrans
 
-def normalize_text(text, table=_table):
+def normalizeText(text, table=_table):
     &quot;&quot;&quot;turns everything to lowercase, and converts accentuated
-    characters to non accentuated chars.&quot;&quot;&quot;
+    characters to non accentuated chars.
+
+    :param text: **unicode** string to normalize
+    &quot;&quot;&quot;
+    assert type(text) is unicode
     text = text.lower().translate(table)
     return ' '.join(text.split())
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000044.html">[Maay-svncheckins] r70 - trunk/maay
</A></li>
	<LI>Next message: <A HREF="000046.html">[Maay-svncheckins] r72 - trunk/maay
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#45">[ date ]</a>
              <a href="thread.html#45">[ thread ]</a>
              <a href="subject.html#45">[ subject ]</a>
              <a href="author.html#45">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/maay-svncheckins">More information about the Maay-svncheckins
mailing list</a><br>
</body></html>
