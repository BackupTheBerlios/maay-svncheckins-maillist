<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Maay-svncheckins] r606 - trunk/maay
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/maay-svncheckins/2005-November/index.html" >
   <LINK REL="made" HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r606%20-%20trunk/maay&In-Reply-To=%3C200511221718.jAMHIl2L021446%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000577.html">
   <LINK REL="Next"  HREF="000579.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Maay-svncheckins] r606 - trunk/maay</H1>
    <B>aurelienc at BerliOS</B> 
    <A HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r606%20-%20trunk/maay&In-Reply-To=%3C200511221718.jAMHIl2L021446%40sheep.berlios.de%3E"
       TITLE="[Maay-svncheckins] r606 - trunk/maay">aurelienc at berlios.de
       </A><BR>
    <I>Tue Nov 22 18:18:47 CET 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="000577.html">[Maay-svncheckins] r605 - trunk/maay
</A></li>
        <LI>Next message: <A HREF="000579.html">[Maay-svncheckins] r607 - in trunk/maay: . data
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#578">[ date ]</a>
              <a href="thread.html#578">[ thread ]</a>
              <a href="subject.html#578">[ subject ]</a>
              <a href="author.html#578">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: aurelienc
Date: 2005-11-22 18:18:47 +0100 (Tue, 22 Nov 2005)
New Revision: 606

Modified:
   trunk/maay/p2pquerier.py
Log:
-small refactoring
-bump p2pquery version number
-add slow background polling of nodes that are sleeping/inactive


Modified: trunk/maay/p2pquerier.py
===================================================================
--- trunk/maay/p2pquerier.py	2005-11-22 17:07:41 UTC (rev 605)
+++ trunk/maay/p2pquerier.py	2005-11-22 17:18:47 UTC (rev 606)
@@ -26,6 +26,7 @@
 import time
 import os
 import socket
+from threading import Thread
 
 from logilab.common.compat import set
 
@@ -36,11 +37,14 @@
 from maay.query import Query
 
 nodeConfig=NodeConfiguration()
-nodeConfig.load()
+nodeConfig.load() #FIXME : load from file would be better
+
 NODE_HOST = socket.gethostbyname(socket.gethostname())
 NODE_PORT = nodeConfig.rpcserver_port
 NODE_ID = nodeConfig.get_node_id()
 
+QUERIER = None
+
 def hashIt(item, uname=''.join(platform.uname())):
     hasher = sha.sha()
     hasher.update(uname)
@@ -65,6 +69,9 @@
         # could not guess username, use host name
         return socket.gethostname()
 
+NODE_LOGIN = getUserLogin()
+
+
 class QueryVersionMismatch(Exception):
     &quot;&quot;&quot;we beginning a versionning nightmare trip on queries
        maybe I'll be shot for this, but who knows&quot;&quot;&quot;
@@ -76,14 +83,14 @@
 # number of results relayed by each peer.
 # This might cause the results to be very incomplete and it will
 # be improved in the future, but for now:
-#  - 50 results per node with a good ranking system is
+#  - 50 results per node with a good ranking system (duh!) is
 #    acceptable
 #  - it should lightweight the network
 LIMIT = 50
 
 class P2pQuery:
 
-    _version = 2
+    _version = 3
     
     def __init__(self, sender, query, ttl=5,
                  qid=None, client_host=None, client_port=None):
@@ -142,12 +149,11 @@
 
     def fromDict(dic):
         &quot;&quot;&quot;dual of asKwargs&quot;&quot;&quot;
-        if dic.has_key('version'):
-            if dic['version'] &gt; P2pQuery._version:
-                print &quot;******* Query Version Mismatch ********&quot;
-                print &quot;(we don't understand queries version %s)&quot; % dic['version']
-                raise QueryVersionMismatch(query_version=dic['version'],
-                                           local_version=P2pQuery._version)
+        if not compatible(P2pQuery._version, dic['version']):
+            print &quot;******* Query Version Mismatch ********&quot;
+            print &quot;(we don't understand queries version %s)&quot; % dic['version']
+            raise QueryVersionMismatch(query_version=dic['version'],
+                                       local_version=P2pQuery._version)
         _query = Query(' '.join(dic['words']), filetype=dic['mime_type'])
         p2pquery = P2pQuery(qid=dic['qid'],
                             sender=dic['sender'],
@@ -162,6 +168,11 @@
         return self.query.words
 
 
+def compatible(localversion, distantversion):
+    if distantversion &lt; 2:
+        return False
+    return True
+
 class P2pAnswer:
     def __init__(self, queryId, provider, documents):
         &quot;&quot;&quot;
@@ -193,6 +204,8 @@
     def __init__(self, nodeId, querier):
         self.nodeId = nodeId  
         self.querier = querier
+        global QUERIER
+        QUERIER = querier # yes, a global
         self._answerCallbacks = {}
         # now, read a config. provided value for EXPIRATION_TIME
         # and fire the garbage collector
@@ -234,8 +247,8 @@
     ######### Callback ops (who to feed the results of a query)
 
     def addAnswerCallback(self, queryId, callback):
-        print &quot;P2pQuerier : registering callback (%s, %s) for results&quot; \
-              % (queryId, callback)
+        #print &quot;P2pQuerier : registering callback (%s, %s) for results&quot; \
+        #      % (queryId, callback)
         self._answerCallbacks.setdefault(queryId, []).append(callback)
 
     def _notifyAnswerCallbacks(self, queryId, provider, results):
@@ -259,7 +272,6 @@
                 continue
             proxy = Proxy(str(neighbor.getRpcUrl()))
             d = proxy.callRemote('distributedQuery', query.asKwargs())
-            d.addCallback(self.querier.registerNodeActivity)
 	    d.addErrback(sendQueryErrback(neighbor, self.querier))
             self._sentQueries[query.qid] = query
             print &quot;     ... sent to %s:%s %s&quot; % (neighbor.ip,
@@ -270,14 +282,13 @@
         &quot;&quot;&quot;
         :type query: `maay.p2pquerier.P2pQuery`
         &quot;&quot;&quot;
-        print &quot;P2pQuerier receiveQuery : %s&quot; % query
         if query.qid in self._receivedQueries or \
            query.qid in self._sentQueries:
-            print &quot; ... we already know query %s, this ends the trip&quot; % query.qid
             return
 
         if query.qid not in self._sentQueries:
-            print &quot; ... %s is a new query, let's work ...&quot; % query.qid
+            print &quot;P2pQuerier receiveQuery : %s from %s:%s &quot; \
+                  % (query.getWords(), query.client_host, query.client_port)
             self._receivedQueries[query.qid] = query 
 
         query.hop()        
@@ -293,9 +304,9 @@
             doc.text = untagText(removeSpace(abstract))
 
         # provider is a 4-uple (login, node_id, IP, xmlrpc-port)
-        provider = (getUserLogin(),
+        provider = (NODE_LOGIN,
                     NODE_ID,
-                    socket.gethostbyname(socket.gethostname()),
+                    NODE_HOST,
                     NODE_PORT)
             
         self.relayAnswer(P2pAnswer(query.qid, provider, documents))
@@ -304,7 +315,10 @@
         &quot;&quot;&quot;record and forward answers to a query.
         If local is True, then the answers come from a local query,
         and thus must not be recorded in the database&quot;&quot;&quot;
-        print &quot;P2pQuerier relayAnswer : %s document(s)&quot; % len(answer.documents)
+        print &quot;P2pQuerier relayAnswer : %s document(s) from %s:%s&quot; \
+              % (len(answer.documents),
+                 answer.provider[1],
+                 answer.provider[2])
         query = self._receivedQueries.get(answer.queryId)
         if not query :
             query = self._sentQueries.get(answer.queryId)
@@ -313,9 +327,15 @@
             else:
                 print &quot; ... bug or dos : we had no query for this answer&quot;
                 return
-        print &quot; ... relaying Answer to %s:%s ...&quot; \
-              % (query.client_host, query.client_port)
-        
+
+            try:
+                self.querier.registerNode(answer.provider[1],
+                                          answer.provider[2],
+                                          answer.provider[3])
+            except:
+                print &quot;  ... version mismatch with %s:%s&quot; \
+                      % (answer.provider[1], answer.provider[2])
+                
         toSend = []
         for document in answer.documents:
             if not isinstance(document, dict):
@@ -330,21 +350,17 @@
                 query.addMatch(document)
                 toSend.append(document)
         
-        if query.sender != self.nodeId: 
-            try:
-                (host, port) = (query.client_host, query.client_port)
-                print &quot; ... will send answer to %s:%s&quot; % (host, port)
-                senderUrl = '<A HREF="http://%s:%s">http://%s:%s</A>' % (host, port)
-                proxy = Proxy(senderUrl)
-                d = proxy.callRemote('distributedQueryAnswer',
-                                     query.qid,
-                                     self.nodeId,
-                                     answer.provider,
-                                     toSend)
-                d.addCallback(self.querier.registerNodeActivity)
-                d.addErrback(answerQueryErrback(query))
-            except ValueError:
-                print &quot; ... unknown node %s&quot; % query.sender
+        if query.sender != self.nodeId:
+            (host, port) = (query.client_host, query.client_port)
+            print &quot; ... relaying Answer to %s:%s ...&quot; % (host, port)
+            senderUrl = '<A HREF="http://%s:%s">http://%s:%s</A>' % (host, port)
+            proxy = Proxy(senderUrl)
+            d = proxy.callRemote('distributedQueryAnswer',
+                                 query.qid,
+                                 self.nodeId,
+                                 answer.provider,
+                                 toSend) 
+            d.addErrback(answerQueryErrback(query))
         else: 
             self._notifyAnswerCallbacks(answer.queryId, answer.provider, toSend)
     
@@ -366,6 +382,7 @@
         &quot;&quot;&quot;
         print &quot; ... problem sending the query to %s:%s, trace = %s&quot; \
               % (target.ip, target.port, failure.getTraceback())
+        registerSleeping(target)
         querier.registerNodeInactivity(target.node_id)
     return QP
 
@@ -376,3 +393,71 @@
         print &quot; ... problem answering the query to %s:%s, trace = %s&quot; \
               % (target.client_host, target.client_port, failure.getTraceback())
     return AP
+
+
+##### Background task that probes periodically sleeping nodes
+
+## The call chain :
+##
+## registerSleeping --(first to sleep ?)--&gt; checkOldest --&gt; backgroundProbe --&gt; nodeSleeps
+##                                          ^                             |
+##                                          |                             |
+##                                          +------(sleeping nodes ?)-----+
+
+SLEEPING_NODES = {}
+CHECK_DELAY = 15 # time in secs before we probe the oldest sleeping node
+
+
+def registerSleeping(node):
+    # beware that not on all platforms we get sub-second values with time()
+    # in this case we risk collisions (checked on Linux &amp; Win2003)
+    print &quot;registerSleeping node %s scheduled for sleep check&quot; % node.node_id
+    stamp = time.time()
+    sleeping = len(SLEEPING_NODES)
+    if sleeping == 0:
+        reactor.callLater(CHECK_DELAY, checkOldest)
+    SLEEPING_NODES [stamp] = node
+
+
+def checkOldest():
+    assert len(SLEEPING_NODES) &gt; 0
+    stamps = SLEEPING_NODES.keys()
+    stamps.sort()
+    old_stamp = stamps[0]
+    old_node = SLEEPING_NODES[old_stamp]
+    del SLEEPING_NODES[old_stamp]
+    thread = Thread(target=backgroundProbe, args=(old_node, old_stamp))
+    thread.start()
+
+
+PROBE_COUNT = 0
+
+def backgroundProbe(node, stamp):
+    now = time.time()
+    global PROBE_COUNT
+    PROBE_COUNT += PROBE_COUNT
+    if nodeSleeps(node.ip, node.port):
+        # we reschedule it
+        if not PROBE_COUNT % 30:
+            print &quot;backgroundProbe node at %s:%s was still sleeping&quot; \
+                  % (node.ip, node.port)
+        now = time.time()
+        SLEEPING_NODES[now] = node
+    else:
+        print &quot;backgroundProbe node at %s:%s has awaken&quot; \
+              % (node.ip, node.port)
+        QUERIER.registerNodeActivity(node.node_id)
+    right_now = time.time()
+    if len(SLEEPING_NODES) &gt; 0:
+        reactor.callLater(abs(CHECK_DELAY - right_now + now), checkOldest)
+
+socket.setdefaulttimeout(3)
+def nodeSleeps(node_ip, node_port):
+    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+    try:
+        s.connect((node_ip, node_port))
+        s.close()
+    except socket.error, exc:
+        return True 
+    else:
+        return False


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000577.html">[Maay-svncheckins] r605 - trunk/maay
</A></li>
	<LI>Next message: <A HREF="000579.html">[Maay-svncheckins] r607 - in trunk/maay: . data
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#578">[ date ]</a>
              <a href="thread.html#578">[ thread ]</a>
              <a href="subject.html#578">[ subject ]</a>
              <a href="author.html#578">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/maay-svncheckins">More information about the Maay-svncheckins
mailing list</a><br>
</body></html>
