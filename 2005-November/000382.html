<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Maay-svncheckins] r406 - trunk/maay
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/maay-svncheckins/2005-November/index.html" >
   <LINK REL="made" HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r406%20-%20trunk/maay&In-Reply-To=%3C200511101417.jAAEH6Lg030890%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000381.html">
   <LINK REL="Next"  HREF="000383.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Maay-svncheckins] r406 - trunk/maay</H1>
    <B>Aur&#233;lien Camp&#233;as at BerliOS</B> 
    <A HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r406%20-%20trunk/maay&In-Reply-To=%3C200511101417.jAAEH6Lg030890%40sheep.berlios.de%3E"
       TITLE="[Maay-svncheckins] r406 - trunk/maay">aurelienc at berlios.de
       </A><BR>
    <I>Thu Nov 10 15:17:06 CET 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="000381.html">[Maay-svncheckins] r405 - trunk/maay
</A></li>
        <LI>Next message: <A HREF="000383.html">[Maay-svncheckins] r407 - in trunk/maay: . test
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#382">[ date ]</a>
              <a href="thread.html#382">[ thread ]</a>
              <a href="subject.html#382">[ subject ]</a>
              <a href="author.html#382">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: aurelienc
Date: 2005-11-10 15:17:06 +0100 (Thu, 10 Nov 2005)
New Revision: 406

Modified:
   trunk/maay/texttool.py
Log:
More pylintification


Modified: trunk/maay/texttool.py
===================================================================
--- trunk/maay/texttool.py	2005-11-10 14:04:59 UTC (rev 405)
+++ trunk/maay/texttool.py	2005-11-10 14:17:06 UTC (rev 406)
@@ -27,26 +27,11 @@
 import mimetypes
 import gzip
 import bz2
-from sets import Set
 
-class LStringIO(list):
-    &quot;&quot;&quot;simple StringIO-like objects using a list
+from maay.image import get_ustring_from_exif, make_thumbnail
+from maay.configuration import ImageConfiguration as ImConfig
 
-    Note: LStringIO should be more or less equivalent to cStrinIO speed-wise
-          but has the great advantage to accept any unicode string
-    &quot;&quot;&quot;
-    def __init__(self):
-        list.__init__(self)
-    write = list.append
-    def getvalue(self):
-        return u''.join(self)
 
-
-from maay.image import get_ustring_from_exif, make_thumbnail,\
-     ThumbnailCreationError
-from maay.configuration import ImageConfiguration as ImConfig, \
-     NoThumbnailsDir
-
 WORD_MIN_LEN = 2
 WORD_MAX_LEN = 50
 
@@ -57,11 +42,23 @@
 
 WORDS_RGX = re.compile(r'\w{%s,%s}' % (WORD_MIN_LEN, WORD_MAX_LEN)) 
 
-
-
 CHARSET_RGX = re.compile(r'charset=[\s&quot;]*([^\s&quot;]+)', re.I | re.S | re.U)
 XML_ENCODING_RGX = re.compile(r'^&lt;\?xml version=[^\s]*\s*encoding=([^\s]*)\s*\?&gt;', re.I | re.S | re.U)
 
+
+class LStringIO(list):
+    &quot;&quot;&quot;simple StringIO-like objects using a list
+       Note: LStringIO should be more or less equivalent to cStrinIO speed-wise
+       but has the great advantage to accept any unicode string
+    &quot;&quot;&quot;
+    def __init__(self):
+        list.__init__(self)
+
+    write = list.append
+
+    def getvalue(self):
+        return u''.join(self)
+
 class ParsingError(Exception):
     &quot;&quot;&quot;raised when an error occurs during the indexation of a file&quot;&quot;&quot;
     pass
@@ -92,28 +89,28 @@
         stream = file(filename, 'rb')
         
     try:
-        buffer = stream.read(4)
+        buffer_ = stream.read(4)
         # try to guess from BOM
-        if buffer[:4] in (codecs.BOM_UTF32_BE, codecs.BOM_UTF32_LE):
+        if buffer_[:4] in (codecs.BOM_UTF32_BE, codecs.BOM_UTF32_LE):
             return 'UTF-32'
-        elif buffer[:2] in (codecs.BOM_UTF16_BE, codecs.BOM_UTF16_LE):
+        elif buffer_[:2] in (codecs.BOM_UTF16_BE, codecs.BOM_UTF16_LE):
             return 'UTF-16'
-        elif buffer[:3] == codecs.BOM_UTF8:
+        elif buffer_[:3] == codecs.BOM_UTF8:
             return 'UTF-8'
-        buffer += stream.read()
+        buffer_ += stream.read()
         if mimetypes.guess_type(filename)[0] == 'text/html':
-            m = CHARSET_RGX.search(buffer)
+            m = CHARSET_RGX.search(buffer_)
             if m is not None :
                 return normalizeHtmlEncoding(m.group(1))
         # check for xml encoding declaration
-        if buffer.lstrip().startswith('&lt;?xml'):
-            m = XML_ENCODING_RGX.match(buffer)
+        if buffer_.lstrip().startswith('&lt;?xml'):
+            m = XML_ENCODING_RGX.match(buffer_)
             if m is not None:
                 return m.group(1)[1:-1].upper()
             # xml files with no encoding declaration default to UTF-8
             return 'UTF-8'
         try:
-            data = unicode(buffer, 'utf-8')
+            _ = unicode(buffer_, 'utf-8')
             return 'UTF-8'
         except UnicodeError:
             return 'ISO-8859-1'
@@ -260,7 +257,7 @@
 
 
 
-for s, d in zip(    list('\xc0\xc1\xc2\xc3\xc4\xc5'
+for _s, _d in zip(    list('\xc0\xc1\xc2\xc3\xc4\xc5'
     '\xc7'
     '\xc8\xc9\xca\xcb'
     '\xcc\xcd\xce\xcf'
@@ -298,7 +295,7 @@
     'uuuu'
     'y'
     )):
-    _table[ord(s)] = ord(d)
+    _table[ord(_s)] = ord(_d)
 
 def normalizeText(text, table=_table):
     &quot;&quot;&quot;turns everything to lowercase, and converts accentuated
@@ -347,7 +344,6 @@
     lastStart = 0
     end = 0
     for occurence in rgx.finditer(text):
-        wordFound = occurence.group(0)
         start, end = occurence.start(), occurence.end()
         if start &gt; 0:
             s.write(&quot; &quot;)
@@ -376,14 +372,9 @@
     
 
 def computeExcerptPositions(text, words):
-    text_length = len(text)
-
-
-
     # quick and dirty regex...
     rgx = re.compile(r'\W' + r'\W|\W'.join(words) + r'\W', re.I)
 
-    #
     # Get the best excerpt for the abstract :
     # - excerpt for most words of the query
     # - first occurence of words
@@ -410,7 +401,7 @@
                 continue
                     
             for i in xrange(len(excerptPositions) - 1, 0, -1):
-                word, position = excerptPositions[i]
+                word, _ = excerptPositions[i]
                 if wordOccurrences[word] == max_occurence:
                     wordOccurrences[word] -= 1
                     if wordOccurrences[word] == 0:


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000381.html">[Maay-svncheckins] r405 - trunk/maay
</A></li>
	<LI>Next message: <A HREF="000383.html">[Maay-svncheckins] r407 - in trunk/maay: . test
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#382">[ date ]</a>
              <a href="thread.html#382">[ thread ]</a>
              <a href="subject.html#382">[ subject ]</a>
              <a href="author.html#382">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/maay-svncheckins">More information about the Maay-svncheckins
mailing list</a><br>
</body></html>
