<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Maay-svncheckins] r642 - trunk/maay
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/maay-svncheckins/2005-November/index.html" >
   <LINK REL="made" HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r642%20-%20trunk/maay&In-Reply-To=%3C200511240946.jAO9ktX7012615%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000613.html">
   <LINK REL="Next"  HREF="000615.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Maay-svncheckins] r642 - trunk/maay</H1>
    <B>adimasci at BerliOS</B> 
    <A HREF="mailto:maay-svncheckins%40lists.berlios.de?Subject=Re%3A%20%5BMaay-svncheckins%5D%20r642%20-%20trunk/maay&In-Reply-To=%3C200511240946.jAO9ktX7012615%40sheep.berlios.de%3E"
       TITLE="[Maay-svncheckins] r642 - trunk/maay">adimasci at berlios.de
       </A><BR>
    <I>Thu Nov 24 10:46:55 CET 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="000613.html">[Maay-svncheckins] r641 - trunk/maay
</A></li>
        <LI>Next message: <A HREF="000615.html">[Maay-svncheckins] r643 - trunk/maay
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#614">[ date ]</a>
              <a href="thread.html#614">[ thread ]</a>
              <a href="subject.html#614">[ subject ]</a>
              <a href="author.html#614">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: adimasci
Date: 2005-11-24 10:46:53 +0100 (Thu, 24 Nov 2005)
New Revision: 642

Modified:
   trunk/maay/indexer.py
   trunk/maay/webapplication.py
Log:
run indexer **locally** when started from indexation page !

Modified: trunk/maay/indexer.py
===================================================================
--- trunk/maay/indexer.py	2005-11-24 09:05:53 UTC (rev 641)
+++ trunk/maay/indexer.py	2005-11-24 09:46:53 UTC (rev 642)
@@ -34,11 +34,12 @@
 import os
 import sys
 import sha
-from sets import Set
 from xmlrpclib import ServerProxy, Fault, ProtocolError
 import mimetypes
 import socket
 
+from logilab.common.compat import set
+
 from zope.interface import Interface
 
 from maay import converter
@@ -107,42 +108,22 @@
         return &quot;Won't index %s because %s&quot; % (self.thefile,
                                               self.cause)
 
- 
-# TODO: manage periodical runs
-# TODO: memorize state of indexed document to avoid db lookup at each run
-# TODO: do an initial db query to initialize the indexation state (?)
-class Indexer:
-    &quot;&quot;&quot;An Indexer instance periodically looks in the configured
-    directories for files to index If it detects changes in known
-    files, it sends a request to the Querier (via xmlrpc) to index the
-    file, giving the Querier information on the file. The querier may
-    decide to do nothing if it detects that the database is up-to-date.
-    &quot;&quot;&quot;
-    
+
+
+class AbstractIndexer:
     def __init__(self, indexerConfig, observers=None):
         self.indexerConfig = indexerConfig
-        username = self.indexerConfig.user
-        password = self.indexerConfig.password
-        host = self.indexerConfig.host
-        port = self.indexerConfig.port
         self.filesystemEncoding = sys.getfilesystemencoding()
-        print &quot;Indexer connecting to Node %s:%s&quot; % (host, port)
-        self.serverProxy = ServerProxy('<A HREF="http://%s:%s">http://%s:%s</A>' % (host, port),
-                                       allow_none=True,
-                                       encoding='utf-8')
-        self.cnxId, errmsg = self.serverProxy.authenticate(username, password)
         self.verbose = indexerConfig.verbose
         self.observers = observers or []
-        if not self.cnxId:
-            if self.verbose:
-                print &quot;Got failure from Node:&quot;, errmsg
-            raise MaayAuthenticationError(&quot;Failed to connect as '%s'&quot; % username)
         # we might be asked to purge everything and just exit
         if indexerConfig['purge']:
             self._purgeEverything()
             sys.exit(0)
             
-        
+    def _purgeEverything(self):
+        raise NotImplementedError('abstract method')
+
     def getFileIterator(self, isPrivate=True):
         if isPrivate:
             indexed = self.indexerConfig.private_dir
@@ -158,43 +139,20 @@
     def isIndexable(self, filename):
         return converter.isKnownType(filename)
 
-    def purgeFiles(self,fileset):
-        for filename in fileset:
-            if self.verbose:
-                print &quot;Requesting unindexation of %s&quot; % \
-                      safe_encode(filename)
-            self.serverProxy.removeFileInfo(self.cnxId, filename)
-        if self.verbose:
-            print &quot;Requesting cleanup of unreferenced documents&quot;
-        self.serverProxy.removeUnreferencedDocuments(self.cnxId)
-
-    def _purgeEverything(self):
-        indexedFiles = Set(self.serverProxy.getIndexedFiles(self.cnxId))
-        self.purgeFiles(indexedFiles)
-
+    def _getIndexedFiles(self):
+        raise NotImplementedError(&quot;abstract method&quot;)
+    
     def start(self):
         # we index private dirs first because public overrides private
         # log.startLogging(open('maay-indexer.log', 'w'))
         existingFiles = self.runIndexer(isPrivate=True)
         existingFiles |= self.runIndexer(isPrivate=False)
-        indexedFiles = Set(self.serverProxy.getIndexedFiles(self.cnxId))
+        indexedFiles = self._getIndexedFiles()
         oldFiles = indexedFiles - existingFiles
         self.purgeFiles(oldFiles)
         for obs in self.observers:
             obs.indexationCompleted()
 
-    def runIndexer(self, isPrivate=True):
-        existingFiles = Set()
-        state = docState(isPrivate)
-        for filename in self.getFileIterator(isPrivate):
-            existingFiles.add(filename)
-            try:
-                self.indexFile(filename, isPrivate)
-            except FileIndexationFailure, fif: # should be catch-all
-                print fif
-                continue
-        return existingFiles
-
     def indexFile(self, filepath, isPrivate=True):
         try:
             if not self.isIndexable(filepath):
@@ -227,9 +185,72 @@
         except Exception, exc:
             raise FileIndexationFailure(safe_encode(filepath),
                                         &quot;an exception %s was raised&quot; % exc)                                        
+    def runIndexer(self, isPrivate=True):
+        existingFiles = set()
+        state = docState(isPrivate)
+        for filename in self.getFileIterator(isPrivate):
+            existingFiles.add(filename)
+            try:
+                self.indexFile(filename, isPrivate)
+            except FileIndexationFailure, fif: # should be catch-all
+                print fif
+                continue
+        return existingFiles
+
+    def getLastIndexationTimeAndState(self, filename):
+        raise NotImplementedError('abstract method')
+
+    def indexDocument(self, futureDoc):
+        raise NotImplementedError('abstract method')
+
+
+# TODO: manage periodical runs
+# TODO: memorize state of indexed document to avoid db lookup at each run
+# TODO: do an initial db query to initialize the indexation state (?)
+class Indexer(AbstractIndexer):
+    &quot;&quot;&quot;An Indexer instance periodically looks in the configured
+    directories for files to index If it detects changes in known
+    files, it sends a request to the Querier (via xmlrpc) to index the
+    file, giving the Querier information on the file. The querier may
+    decide to do nothing if it detects that the database is up-to-date.
+    &quot;&quot;&quot;
+    
+    def __init__(self, indexerConfig, observers=None):
+        username = self.indexerConfig.user
+        password = self.indexerConfig.password
+        host = self.indexerConfig.host
+        port = self.indexerConfig.port
+        print &quot;Indexer connecting to Node %s:%s&quot; % (host, port)        
+        self.serverProxy = ServerProxy('<A HREF="http://%s:%s">http://%s:%s</A>' % (host, port),
+                                       allow_none=True,
+                                       encoding='utf-8')
+        self.cnxId, errmsg = self.serverProxy.authenticate(username, password)
+        if not self.cnxId:
+            if self.verbose:
+                print &quot;Got failure from Node:&quot;, errmsg
+            raise MaayAuthenticationError(&quot;Failed to connect as '%s'&quot; % username)
+        # baseclass's __init__ must be called *after* local initialisation
+        # otherwise it could call _purgeEverything with an inconsistent state
+        AbstractIndexer.__init__(self, indexerConfig, observers)
+        
+    def purgeFiles(self,fileset):
+        for filename in fileset:
+            if self.verbose:
+                print &quot;Requesting unindexation of %s&quot; % \
+                      safe_encode(filename)
+            self.serverProxy.removeFileInfo(self.cnxId, filename)
+        if self.verbose:
+            print &quot;Requesting cleanup of unreferenced documents&quot;
+        self.serverProxy.removeUnreferencedDocuments(self.cnxId)
+
+    def _purgeEverything(self):
+        indexedFiles = set(self.serverProxy.getIndexedFiles(self.cnxId))
+        self.purgeFiles(indexedFiles)
+
+    def _getIndexedFiles(self):
+        return set(self.serverProxy.getIndexedFiles(self.cnxId))
        
     def getLastIndexationTimeAndState(self, filename):
-        filename = filename
         answer = self.serverProxy.lastIndexationTimeAndState(self.cnxId, filename)
         if answer is None:
             raise MaayAuthenticationError(&quot;Bad cnxId sent to the Node&quot;)
@@ -260,6 +281,66 @@
         for obs in self.observers:
             obs.newDocumentIndexed(futureDoc.filename, futureDoc.state)
 
+class LocalIndexer(AbstractIndexer):
+    &quot;&quot;&quot;special indexer that is meant to run locally, using
+    a querier instance rather than connecting to a RPC server
+    &quot;&quot;&quot;    
+    def __init__(self, indexerConfig, querier, nodeId, observers=None):
+        self.querier = querier
+        self.nodeId = nodeId
+        # baseclass's __init__ must be called *after* local initialisation
+        # otherwise it could call _purgeEverything with an inconsistent state
+        AbstractIndexer.__init__(self, indexerConfig, observers)
+        self.verbose = True
+    
+    def purgeFiles(self, fileset):
+        for filename in fileset:
+            if self.verbose:
+                print &quot;[local] Requesting unindexation of %s&quot; % \
+                      safe_encode(filename)
+            self.querier.removeFileInfo(filename)
+        if self.verbose:
+            print &quot;[local] Requesting cleanup of unreferenced documents&quot;
+        self.querier.removeUnreferencedDocuments()
+
+    def _purgeEverything(self):
+        indexedFiles = set(self.querier.getIndexedFiles())
+        self.purgeFiles(indexedFiles)
+
+    def _getIndexedFiles(self):
+        return set(self.querier.getIndexedFiles())
+       
+    def getLastIndexationTimeAndState(self, filename):
+        fileInfos = self.querier.getFileInformations(filename)
+        if len(fileInfos):
+            return fileInfos[0].file_time, fileInfos[0].state
+        else:
+            return 0, Document.UNKNOWN_STATE
+
+    def indexDocument(self, futureDoc):
+        futureDoc.file_state=FileInfo.CREATED_FILE_STATE
+        if self.verbose:
+            print &quot;[local] Requesting indexation of %s&quot; % \
+                  safe_encode(futureDoc.filename),
+        try:
+            futureDoc.title = removeControlChar(futureDoc.title) 
+            futureDoc.text = removeControlChar(futureDoc.text)
+            if self.verbose:
+                print '[local] ('+safe_encode(futureDoc.title)+')'
+            self.querier.indexDocument(self.nodeId, futureDoc)
+        except Exception, exc:
+            if self.verbose:
+                print &quot;[local] An error occured on the Node while indexing %s&quot; % \
+                      safe_encode(futureDoc.filename)
+                print exc
+                print &quot;[local] See Node log for details&quot;
+            else:
+                print &quot;[local] Error indexing %s: %s&quot; % \
+                      (safe_encode(futureDoc.filename), exc)
+        for obs in self.observers:
+            obs.newDocumentIndexed(futureDoc.filename, futureDoc.state)
+    
+
 ######### FileIterator
 
 if sys.platform == 'win32':
@@ -331,37 +412,31 @@
     print '** is_running()', indexer_thread
     return indexer_thread and indexer_thread.isAlive()
 
-def start_as_thread(webpage):
+def runLocally(querier, nodeId, observers=None):
+    indexer = LocalIndexer(indexerConfig, querier, nodeId, observers)
+    indexer.start()
+    
+def start_as_thread(maayQuerier, nodeId, webpage):
     global indexer_thread
     if is_running():
         print &quot;Indexer already running&quot;, indexer_thread
     else:
         print &quot;launching indexer&quot;
-        indexer_thread = Thread(target=run, args=([webpage],))
+        indexer_thread = Thread(target=runLocally, args=(maayQuerier, nodeId, [webpage],))
         indexer_thread.start()
 
 # index one file from webapp in a thread
 
-def indexJustOneFile(filepath):
-    thread = Thread(target=_just_one, args=(filepath,))
+def indexJustOneFile(maayQuerier, nodeId, filepath):
+    thread = Thread(target=_just_one, args=(maayQuerier, nodeId, filepath))
     thread.start()
 
-def _just_one(filepath):
-    indexerConfig = IndexerConfiguration()
-    indexerConfig.load()
+def _just_one(querier, nodeId, filepath):
+    indexer = LocalIndexer(indexerConfig, querier, nodeId)
+    print 'going to index file %s', filepath
     try:
-        try:
-            indexer = Indexer(indexerConfig)
-        except MaayAuthenticationError, exc:
-            print &quot;AuthenticationError:&quot;, exc
-            return
-        print 'going to index file %s', filepath
         # log.startLogging(open('maay-indexer.log', 'w'))
         indexer.indexFile(filepath, isPrivate=False)
-    except socket.error, exc:
-        print &quot;Cannot contact Node:&quot;, exc
-        print &quot;Check that the Node is running on %s:%s&quot; % \
-              (indexerConfig.host, indexerConfig.port)
     except FileIndexationFailure, fif:
         print fif
 

Modified: trunk/maay/webapplication.py
===================================================================
--- trunk/maay/webapplication.py	2005-11-24 09:05:53 UTC (rev 641)
+++ trunk/maay/webapplication.py	2005-11-24 09:46:53 UTC (rev 642)
@@ -234,7 +234,9 @@
         if (self.untouchedDocuments % 10) == 0:
             for webpage in self.clients.itervalues():
                 webpage.countersUpdated(self.untouchedDocuments,
-                                        self.indexedDocuments)
+                                        self.indexedDocuments,
+                                        self.privateDocuments,
+                                        self.publicDocuments)
     
     def indexationCompleted(self):
         for webpage in self.clients.itervalues():
@@ -357,7 +359,7 @@
                 msg = &quot;Indexer already running&quot;
             else:
                 msg = &quot;Indexer started&quot;
-                indexer.start_as_thread(_factory)
+                indexer.start_as_thread(self.querier, self.maayId, _factory)
         indexationPage.msg = msg
         indexationPage.alertmessage = alertMsg
         return indexationPage
@@ -408,7 +410,7 @@
         f=file(filepath,'wb')
         f.write(fileData)
         f.close()
-        return DistantFilePage(filepath)
+        return DistantFilePage(self.querier, self.maayId, filepath)
 
     def onDownloadFileError(self, error, filename):
         msg = &quot;Error while downloading file: %s&quot; % (filename,)
@@ -434,10 +436,10 @@
             return self.onDownloadFileError('no provider available', filename)
     
 class DistantFilePage(static.File):
-    def __init__(self, filepath):
+    def __init__(self, querier, nodeId, filepath):
         static.File.__init__(self, filepath)
         self.filepath = filepath
-        indexer.indexJustOneFile(self.filepath)
+        indexer.indexJustOneFile(querier, nodeId, self.filepath)
 
 class ResultsPageMixIn:
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000613.html">[Maay-svncheckins] r641 - trunk/maay
</A></li>
	<LI>Next message: <A HREF="000615.html">[Maay-svncheckins] r643 - trunk/maay
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#614">[ date ]</a>
              <a href="thread.html#614">[ thread ]</a>
              <a href="subject.html#614">[ subject ]</a>
              <a href="author.html#614">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/maay-svncheckins">More information about the Maay-svncheckins
mailing list</a><br>
</body></html>
